{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/muneerah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/muneerah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score, average_precision_score,recall_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///message_category.db')\n",
    "conn = engine.connect()\n",
    "df = pd.read_sql_table('message_category',conn)\n",
    "X = df['message']\n",
    "Y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216,)\n",
      "(26216, 36)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    clean_token =  []\n",
    "    for token in tokens:\n",
    "        clean_token.append(lemmatizer.lemmatize(token).lower().strip())\n",
    "        \n",
    "    return clean_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(KNeighborsClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x125f38820>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=KNeighborsClassifier()))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3)\n",
    "\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,column in enumerate(y_test.columns):\n",
    "    print('report for {}'.format(column))\n",
    "    print(classification_report(y_test[column].values.astype(str),y_pred[:,i].astype(int).astype(str)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,column in enumerate(y_test.columns):\n",
    "    print('report for {}'.format(column))\n",
    "    print('accuracy score:',accuracy_score(y_test[column].values.astype(str),y_pred[:,i].astype(int).astype(str)))\n",
    "    print('average_precision_score:',average_precision_score(y_test[column].values.astype(int),y_pred[:,i].astype(int)), '\\n')\n",
    "#     print('accuracy score:',recall_score(y_test[column].values.astype(int),y_pred[:,i].astype(int)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'clf__estimator__n_neighbors':(4, 5)\n",
    "        }\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "\n",
    "cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__max_depth': None, 'clf__max_features': 0.7, 'clf__min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy , precision and recall\n",
    "grid_ypred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report for related\n",
      "accuracy score: 0.804958677686\n",
      "average_precision_score: 0.409820485808\n",
      "accuracy score: 0.454496499731 \n",
      "\n",
      "report for request\n",
      "accuracy score: 0.890654799746\n",
      "average_precision_score: 0.491447170322\n",
      "accuracy score: 0.507947976879 \n",
      "\n",
      "report for offer\n",
      "accuracy score: 0.993897012079\n",
      "average_precision_score: 0.00610298792117\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for aid_related\n",
      "accuracy score: 0.740750158932\n",
      "average_precision_score: 0.603501471387\n",
      "accuracy score: 0.515086206897 \n",
      "\n",
      "report for medical_help\n",
      "accuracy score: 0.922695486332\n",
      "average_precision_score: 0.130978804745\n",
      "accuracy score: 0.0816326530612 \n",
      "\n",
      "report for medical_products\n",
      "accuracy score: 0.95041322314\n",
      "average_precision_score: 0.11130497461\n",
      "accuracy score: 0.0924574209246 \n",
      "\n",
      "report for search_and_rescue\n",
      "accuracy score: 0.974316592498\n",
      "average_precision_score: 0.0739466365538\n",
      "accuracy score: 0.0566037735849 \n",
      "\n",
      "report for security\n",
      "accuracy score: 0.983598219962\n",
      "average_precision_score: 0.0162746344565\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for military\n",
      "accuracy score: 0.970629370629\n",
      "average_precision_score: 0.12750746661\n",
      "accuracy score: 0.172131147541 \n",
      "\n",
      "report for child_alone\n",
      "accuracy score: 1.0\n",
      "average_precision_score: nan\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for water\n",
      "accuracy score: 0.958804831532\n",
      "average_precision_score: 0.428639747542\n",
      "accuracy score: 0.509803921569 \n",
      "\n",
      "report for food\n",
      "accuracy score: 0.940368722187\n",
      "average_precision_score: 0.537206948895\n",
      "accuracy score: 0.602040816327 \n",
      "\n",
      "report for shelter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/ranking.py:444: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.935791481246\n",
      "average_precision_score: 0.335256709464\n",
      "accuracy score: 0.331395348837 \n",
      "\n",
      "report for clothing\n",
      "accuracy score: 0.983852511125\n",
      "average_precision_score: 0.0406357279085\n",
      "accuracy score: 0.0307692307692 \n",
      "\n",
      "report for money\n",
      "accuracy score: 0.976605212969\n",
      "average_precision_score: 0.029785029785\n",
      "accuracy score: 0.0222222222222 \n",
      "\n",
      "report for missing_people\n",
      "accuracy score: 0.989828353465\n",
      "average_precision_score: 0.0265054063034\n",
      "accuracy score: 0.0246913580247 \n",
      "\n",
      "report for refugees\n",
      "accuracy score: 0.96617927527\n",
      "average_precision_score: 0.0576133298094\n",
      "accuracy score: 0.0486891385768 \n",
      "\n",
      "report for death\n",
      "accuracy score: 0.96312778131\n",
      "average_precision_score: 0.152766299357\n",
      "accuracy score: 0.157407407407 \n",
      "\n",
      "report for other_aid\n",
      "accuracy score: 0.873617291799\n",
      "average_precision_score: 0.200874267166\n",
      "accuracy score: 0.146551724138 \n",
      "\n",
      "report for infrastructure_related\n",
      "accuracy score: 0.937190082645\n",
      "average_precision_score: 0.0698899186937\n",
      "accuracy score: 0.0161943319838 \n",
      "\n",
      "report for transport\n",
      "accuracy score: 0.9548633185\n",
      "average_precision_score: 0.0672595378478\n",
      "accuracy score: 0.0448179271709 \n",
      "\n",
      "report for buildings\n",
      "accuracy score: 0.953210425938\n",
      "average_precision_score: 0.0755219920221\n",
      "accuracy score: 0.0536193029491 \n",
      "\n",
      "report for electricity\n",
      "accuracy score: 0.981563890655\n",
      "average_precision_score: 0.0180546726001\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for tools\n",
      "accuracy score: 0.994405594406\n",
      "average_precision_score: 0.00559440559441\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for hospitals\n",
      "accuracy score: 0.990464081373\n",
      "average_precision_score: 0.0226938133637\n",
      "accuracy score: 0.0131578947368 \n",
      "\n",
      "report for shops\n",
      "accuracy score: 0.994151303242\n",
      "average_precision_score: 0.00584869675779\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for aid_centers\n",
      "accuracy score: 0.988938334393\n",
      "average_precision_score: 0.0108073744437\n",
      "accuracy score: 0.0 \n",
      "\n",
      "report for other_infrastructure\n",
      "accuracy score: 0.957024793388\n",
      "average_precision_score: 0.0462818002068\n",
      "accuracy score: 0.00890207715134 \n",
      "\n",
      "report for weather_related\n",
      "accuracy score: 0.858232676414\n",
      "average_precision_score: 0.611516526053\n",
      "accuracy score: 0.58747099768 \n",
      "\n",
      "report for floods\n",
      "accuracy score: 0.946344564526\n",
      "average_precision_score: 0.416290020743\n",
      "accuracy score: 0.423368740516 \n",
      "\n",
      "report for storm\n",
      "accuracy score: 0.935282898919\n",
      "average_precision_score: 0.388512345492\n",
      "accuracy score: 0.463245492372 \n",
      "\n",
      "report for fire\n",
      "accuracy score: 0.987794024158\n",
      "average_precision_score: 0.0305083857099\n",
      "accuracy score: 0.0309278350515 \n",
      "\n",
      "report for earthquake\n",
      "accuracy score: 0.964526382708\n",
      "average_precision_score: 0.644123876534\n",
      "accuracy score: 0.714488636364 \n",
      "\n",
      "report for cold\n",
      "accuracy score: 0.980546726001\n",
      "average_precision_score: 0.0766538736236\n",
      "accuracy score: 0.0679012345679 \n",
      "\n",
      "report for other_weather\n",
      "accuracy score: 0.947997457088\n",
      "average_precision_score: 0.0768549076568\n",
      "accuracy score: 0.0645161290323 \n",
      "\n",
      "report for direct_report\n",
      "accuracy score: 0.862809917355\n",
      "average_precision_score: 0.445244736166\n",
      "accuracy score: 0.444948186528 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,column in enumerate(y_test.columns):\n",
    "    print('report for {}'.format(column))\n",
    "#     print(classification_report(y_test[column].values.astype(str),y_pred[:,i].astype(int).astype(str)), '\\n')\n",
    "    print('accuracy score:',accuracy_score(y_test[column].values.astype(str),grid_ypred[:,i].astype(int).astype(str)))\n",
    "    print('average_precision_score:',average_precision_score(y_test[column].values.astype(int),grid_ypred[:,i].astype(int)))\n",
    "    print('accuracy score:',recall_score(y_test[column].values.astype(int),grid_ypred[:,i].astype(int)), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle    \n",
    "    \n",
    "filename = 'GridSearchv_disaster_model.sav'\n",
    "pickle.dump(cv, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
